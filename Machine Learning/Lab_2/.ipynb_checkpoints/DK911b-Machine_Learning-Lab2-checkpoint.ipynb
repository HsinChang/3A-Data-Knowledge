{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Lab 2\n",
    "\n",
    " - scikit-learn is the leading machine learning software in Python\n",
    " - scikit-learn is a project started in Paris, Inria and Telecom Paris\n",
    " - scilkit-learn is easy to use and extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZHANG Xin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1:\n",
    "### - Implement a majority class classifier: a classifier that predicts the class label that is most frequent in the dataset.\n",
    "\n",
    "- Classifiers in scikit-learn has two main methods:\n",
    "    - Build a model: fit(self, X, Y)\n",
    "    - Make a prediction: predict(self, X)\n",
    "    \n",
    "- Template for implementing classifier is given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NewClassifier:\n",
    "    def __init__(self):\n",
    "        self.num = 0\n",
    "    def fit(self, X, Y):\n",
    "        if isinstance(Y, np.ndarray) and len(Y.shape) > 1 and Y.shape[1] > 1:\n",
    "            raise NotImplementedError('Majority class classifier not supported')\n",
    "        \n",
    "        counts = np.bincount(Y)\n",
    "        self.num = np.argmax(counts)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        for i in range(0,X.shape[0]):\n",
    "            Y.append(self.num)\n",
    "        \n",
    "        return Y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test if the classifier works**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NewClassifier()\n",
    "clf.fit(np.empty(shape=(3,3)),np.array([0,0,1]))\n",
    "clf.predict(np.empty(shape=(4,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "     \n",
    "# Task 2:\n",
    "### - Implement k-fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def cross_validation(clf, dataset, n_folds):\n",
    "    #data initialization\n",
    "    X = dataset.data\n",
    "    y = dataset.target\n",
    "    X_sparse = coo_matrix(X)\n",
    "    data_X, X_sparse, data_y = shuffle(X, X_sparse, y)\n",
    "    k = n_folds\n",
    "    training_list = []\n",
    "    class_list = []\n",
    "    spilt_size = int(data_X.shape[0] / k)\n",
    "    \n",
    "    #Spilt the data and classes into N parts in two lists\n",
    "    for i in range(0, k):\n",
    "        training_list.append(data_X[i * spilt_size:(i + 1) * spilt_size])\n",
    "        class_list.append(data_y[i * spilt_size:(i + 1) * spilt_size])\n",
    "    \n",
    "    #begin the validation with the split from former step\n",
    "    sum_accuracy = 0\n",
    "    for i in range(0, k):\n",
    "        temp_training = []\n",
    "        temp_class = []\n",
    "        temp_test = []\n",
    "        temp_class_test = []\n",
    "        for j in range(0, k):\n",
    "            if (j != i):\n",
    "                temp_training.extend(training_list[j])\n",
    "                temp_class.extend(class_list[j])\n",
    "            else:\n",
    "                temp_test.extend(training_list[j])\n",
    "                temp_class_test.extend(class_list[j])\n",
    "        temp_training = np.concatenate(temp_training, axis= 0)\n",
    "        temp_training = np.reshape(temp_training, (spilt_size * (k -1),data_X.shape[1]))\n",
    "        temp_test = np.concatenate(temp_test, axis = 0)\n",
    "        temp_test = np.reshape(temp_test, (spilt_size,data_X.shape[1]))\n",
    "        temp_class = np.array(temp_class)\n",
    "        temp_class_test = np.array(temp_class_test)\n",
    "        clf.fit(temp_training, temp_class)\n",
    "        temp_predicted = clf.predict(temp_test)\n",
    "        sum_accuracy += accuracy_score(temp_class_test, temp_predicted)\n",
    "    score = sum_accuracy/k\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can be way shorter if `sklearn.model_selection.train_test_split(*arrays, **options)` is used. But it's better to implement from basic `python` and `numpy` commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test if it works properly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251700680272109"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import datasets\n",
    "knn = KNeighborsClassifier()\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "cross_validation(knn,iris,7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "### Use the majority class classifier to evaluate one dataset, and explain the evaluation results:\n",
    "\n",
    "- https://scikit-learn.org/stable/datasets/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NewClassifier()\n",
    "cross_validation(clf,iris,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the result, let us firstly check the number of each classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 50 50]\n"
     ]
    }
   ],
   "source": [
    "y = iris.target\n",
    "counts_1 = np.bincount(y)\n",
    "print(counts_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that in the iris dataset, the number of the three classes (0,1,2) are all 50. So, In each step of the cross-validation, we suppose that we take $a$ samples from class A, $b$ from class B, $c$ from class C for the test. So we have $a+b+c = \\frac{150}{k}$, let us suppose $a>b>c$, so $c$ will be the majority class in the training as less $c$ is taken into test set.\n",
    "And $c<\\frac{50}{k}$, so we get\n",
    "$$accurary = \\frac{c \\times k}{150}<\\frac{50}{150}<\\frac{1}{3}$$\n",
    "So for the iris dataset with the majority class classifier, the accuracy cannot be larger than $\\frac{1}{3}$, or for each dataset, the accuracy cannot be larger than $\\frac{1}{No. classes}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: ***OPTIONAL*** \n",
    "\n",
    "### - Implement another classifier with higher performance than the majority class classifier, evaluate it and comment the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we have analysed earlier, if we just want a better performance form the `iris` dataset, we can just take the minority class instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BetterClassifierForIris:\n",
    "    def __init__(self):\n",
    "        self.num = 0\n",
    "    def fit(self, X, Y):\n",
    "        if isinstance(Y, np.ndarray) and len(Y.shape) > 1 and Y.shape[1] > 1:\n",
    "            raise NotImplementedError('Majority class classifier not supported')\n",
    "        \n",
    "        counts = np.bincount(Y)\n",
    "        self.num = np.argmin(counts)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        for i in range(0,X.shape[0]):\n",
    "            Y.append(self.num)\n",
    "        \n",
    "        return Y\n",
    "    \n",
    "clf = BetterClassifierForIris()\n",
    "cross_validation(clf,iris,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more general case, we can just perform a linear regression with $X$ and $y$ and keep the `int` value by rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterClassifier:\n",
    "    def __init__(self, alpha=0.03, n_iter=1500):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.n_iter = n_iter\n",
    "        self.params = []\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.n_samples = 0\n",
    "        self.n_features = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_samples = len(y)\n",
    "        self.n_features = np.size(X, 1)\n",
    "        self.params = np.zeros((self.n_features + 1, 1))\n",
    "        self.X = np.hstack((np.ones(\n",
    "            (self.n_samples, 1)), (X - np.mean(X, 0)) / np.std(X, 0)))\n",
    "        self.y = y[:, np.newaxis]\n",
    "        for i in range(self.n_iter):\n",
    "            self.params = self.params - (self.alpha/self.n_samples) * \\\n",
    "            self.X.T @ (self.X @ self.params - self.y)\n",
    "\n",
    "        self.intercept_ = self.params[0]\n",
    "        self.coef_ = self.params[1:]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n_samples = np.size(X, 0)\n",
    "        y = np.hstack((np.ones((n_samples, 1)), (X-np.mean(X, 0)) \\\n",
    "                            / np.std(X, 0))) @ self.params\n",
    "        y = [int(i) for i in y.T[0]]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6533333333333333"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BetterClassifier()\n",
    "cross_validation(clf,iris,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the performance is better with a simple linear regression. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
